{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (1726070797.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[16], line 1\u001b[0;36m\u001b[0m\n\u001b[0;31m    ---\u001b[0m\n\u001b[0m       ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "---\n",
    "  title: \"HW 02\"\n",
    "  author: \"INSERT YOUR NAME HERE\"\n",
    "  format:\n",
    "    html:\n",
    "      embed-resources: true\n",
    "  toc: true\n",
    "  jupyter: python3\n",
    "  ---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Setup and Data Preprocessing\n",
    "\n",
    "- Start by importing the necessary libraries and load the spam.csv dataset.\n",
    "\n",
    "- Preprocess the data by encoding categorical variables, defining features and target, and splitting the data into training and testing sets. Finally, apply PCA to reduce dimensionality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, roc_curve, auc\n",
    "from sklearn.preprocessing import label_binarize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "spam = pd.read_csv(\"data/spam.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode categorical variables\n",
    "categorical_columns = spam.select_dtypes(include = ['object', 'category']).columns.tolist()\n",
    "label_encoders = {col: LabelEncoder() for col in categorical_columns}\n",
    "for col in categorical_columns:\n",
    "    spam[col] = label_encoders[col].fit_transform(spam[col])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define features and target\n",
    "X = spam.drop('yesno', axis = 1)\n",
    "y = spam['yesno']\n",
    "\n",
    "\n",
    "# Split the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 42)\n",
    "\n",
    "# Reduce dimensionality\n",
    "pca = PCA(n_components = 2)\n",
    "X_train_pca = pca.fit_transform(X_train)\n",
    "X_test_pca = pca.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define features and target\n",
    "X = spam.drop('yesno', axis = 1)\n",
    "y = spam['yesno']\n",
    "\n",
    "\n",
    "# Split the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Model Training and Decision Boundary Visualization\n",
    "\n",
    "- Train a Decision Tree classifier on the PCA-transformed training data.\n",
    "\n",
    "- Implement and use the `decisionplot` function (from the lecture) to visualize the decision boundary of your trained model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decisionplot(model, X, y, resolution=216):\n",
    "    # Split the data into features (X) and the class variable (y)\n",
    "    x_min, x_max = X.iloc[:, 0].min() - 1, X.iloc[:, 0].max() + 1\n",
    "    y_min, y_max = X.iloc[:, 1].min() - 1, X.iloc[:, 1].max() + 1\n",
    "    xx, yy = np.meshgrid(np.linspace(x_min, x_max, resolution),\n",
    "                         np.linspace(y_min, y_max, resolution))\n",
    "\n",
    "    # Predict outcomes for each point on the grid\n",
    "    if isinstance(model, LinearDiscriminantAnalysis):\n",
    "        # For LDA, we need to use the decision_function method\n",
    "        Z = model.decision_function(np.c_[xx.ravel(), yy.ravel()])\n",
    "    else:\n",
    "        Z = model.predict(np.c_[xx.ravel(), yy.ravel()])\n",
    "    \n",
    "    if isinstance(model, LinearDiscriminantAnalysis):\n",
    "    # Reshape LDA decision function output appropriately\n",
    "        Z = Z.reshape(-1, 1)\n",
    "    else:\n",
    "        Z = Z.reshape(xx.shape)\n",
    "\n",
    "    # Plot the actual data points\n",
    "    plt.scatter(X.iloc[:, 0], X.iloc[:, 1], c=y, edgecolors='k', s=20)\n",
    "\n",
    "    # Overlay the decision boundary\n",
    "    plt.contourf(xx, yy, Z, alpha = 0.5)\n",
    "    \n",
    "    # Calculate the accuracy\n",
    "    predictions = model.predict(X)\n",
    "    acc = accuracy_score(y, predictions)\n",
    "    \n",
    "  \n",
    "    # Set labels for axes\n",
    "    plt.xlabel(X.columns[0])\n",
    "    plt.ylabel(X.columns[1])\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>DecisionTreeClassifier()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">DecisionTreeClassifier</label><div class=\"sk-toggleable__content\"><pre>DecisionTreeClassifier()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "DecisionTreeClassifier()"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| eval: false\n",
    "\n",
    "\n",
    "# Train Decision Tree\n",
    "dtree = DecisionTreeClassifier()\n",
    "# dtree.fit(X_train_pca, y_train)\n",
    "dtree.fit(X_train, y_train)\n",
    "\n",
    "# Implement the decisionplot function (as provided in the lecture content)\n",
    "# Add the decisionplot function here\n",
    "\n",
    "# Visualize decision boundary\n",
    "# decisionplot(dtree, pd.DataFrame(X_train_pca, columns = ['PC1', 'PC2']), y_train)\n",
    "# decisionplot(dtree, X_train, y_train)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Model Evaluation\n",
    "\n",
    "- Evaluate your model using accuracy, precision, recall, F1 score, and AUC-ROC metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.83\n",
      "Precision: 0.83\n",
      "Recall: 0.83\n",
      "F1 Score: 0.83\n"
     ]
    }
   ],
   "source": [
    "#| eval: false\n",
    "\n",
    "\n",
    "# Predictions\n",
    "# predictions = dtree.predict(X_test_pca)\n",
    "predictions = dtree.predict(X_test)\n",
    "\n",
    "# Evaluate metrics\n",
    "accuracy = accuracy_score(y_test, predictions)\n",
    "precision = precision_score(y_test, predictions, average = 'weighted')\n",
    "recall = recall_score(y_test, predictions, average = 'weighted')\n",
    "f1 = f1_score(y_test, predictions, average = 'weighted')\n",
    "\n",
    "# Display results\n",
    "print(f\"Accuracy: {accuracy:.2f}\")\n",
    "print(f\"Precision: {precision:.2f}\")\n",
    "print(f\"Recall: {recall:.2f}\")\n",
    "print(f\"F1 Score: {f1:.2f}\")\n",
    "\n",
    "# For AUC-ROC, binarize the output and calculate AUC-ROC for each class\n",
    "# Add the necessary code for AUC-ROC calculation here (refer to lecture content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Macro-average ROC-AUC: 0.23\n",
      "Micro-average ROC-AUC: 0.77\n"
     ]
    }
   ],
   "source": [
    "# Binarize the output for multiclass\n",
    "y_test_binarized = label_binarize(y_test, classes = np.unique(y_train))\n",
    "n_classes = y_test_binarized.shape[1]\n",
    "\n",
    "# Get the probability predictions for each class\n",
    "y_score = dtree.predict_proba(X_test_pca)\n",
    "\n",
    "# Compute ROC curve and ROC area for each class\n",
    "fpr = dict()\n",
    "tpr = dict()\n",
    "roc_auc = dict()\n",
    "for i in range(n_classes):\n",
    "    fpr[i], tpr[i], _ = roc_curve(y_test_binarized[:, i], y_score[:, i])\n",
    "    roc_auc[i] = auc(fpr[i], tpr[i])\n",
    "\n",
    "# Calculate macro-average ROC-AUC\n",
    "roc_auc_macro = np.mean(list(roc_auc.values()))\n",
    "print(f\"Macro-average ROC-AUC: {roc_auc_macro:.2f}\")\n",
    "\n",
    "# Calculate micro-average ROC-AUC\n",
    "fpr[\"micro\"], tpr[\"micro\"], _ = roc_curve(y_test_binarized.ravel(), y_score[:,1].ravel())\n",
    "roc_auc_micro = auc(fpr[\"micro\"], tpr[\"micro\"])\n",
    "print(f\"Micro-average ROC-AUC: {roc_auc_micro:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.95652174, 0.04347826],\n",
       "       [1.        , 0.        ],\n",
       "       [1.        , 0.        ],\n",
       "       ...,\n",
       "       [0.66666667, 0.33333333],\n",
       "       [1.        , 0.        ],\n",
       "       [1.        , 0.        ]])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(921, 2)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_pca.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(921,)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(921, 2)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_score.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.95652174, 0.04347826],\n",
       "       [1.        , 0.        ],\n",
       "       [1.        , 0.        ],\n",
       "       ...,\n",
       "       [0.66666667, 0.33333333],\n",
       "       [1.        , 0.        ],\n",
       "       [1.        , 0.        ]])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(921, 1)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test_binarized.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assignment:\n",
    "- Implement the missing parts of the code: the decisionplot function and AUC-ROC calculation.\n",
    "\n",
    "- Discuss the results among your peers. Consider the following:\n",
    "\n",
    "    - Which metric is most informative for this problem and why? It's surprising that the four Accuracy, Precision,Recall, and F1 Score yield the same value, so I prefer to use ROC-AUC metric.\n",
    "\n",
    "    - How does the decision boundary visualization help in understanding the model’s performance? In fact, the decision boundary just shows a very general view of how the data can be visualized, but it is not helpful. Also, when we use all the variables and we have more than 3 dimension, the decision boundary can't show anything. \n",
    "\n",
    "    - Reflect on the impact of PCA on model performance and decision boundary.\n",
    "    Not using PCA yield higher classification performance! All the metrics were increased!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Ali_RS",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
